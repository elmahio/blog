{
    "docs": [
        {
            "location": "/Building-a-salable-architecture-to-handle-millions-of-errors/", 
            "text": "Building a salable architecture to handle millions of errors\n\n\nYou may take it for granted, but building an architecture which is able to scale to millions of messages isn\u2019t something that comes overnight. elmah.io is built to handle lots and lots of messages by utilizing some of the nice features of Windows Azure. In this post we\u2019ll show you how we\u2019ve designed elmah.io to consume errors from our customers.\n\n\nDuring the last 1\u00bd years, we\u2019ve continuously improved our architecture to handle an increasing load. Like every other startup, we didn\u2019t have the perfect architecture from day one. But we learned from our mistakes and now have a scalable architecture, which is able to handle our customer\u2019s data. A picture is worth a thousand words, and that is why looking at a diagram is probably the best way to explain our architecture:\n\n\n\n\nThe diagram illustrates the message flow from receiving a message (typically an error) from a customer, until the entire thing is persisted in the backend. We have a few components for handling emails and business rules that are not included in the diagram in order to keep it simple.\n\n\nAll messages are received through our \nAPI\n. The API is running as part of the elmah.io web application as an Azure Website. Azure Websites have a nice scaling feature, which makes it possible to increase the number of instances dynamically, based on the load on the web server. Since we don\u2019t do much other than send messages to the service bus, we rarely need to scale the number of webservers, but in situations where one of our customers experience a DDOS attack, they may indirectly start DOS attacking us by sending a lot of errors to the elmah.io API. In these situations, scaling this number of websites is extremely important, to avoid the remaining customers being punished by a single DDOS. We rely on Windows Azures to load balancers to handle any DDOS attacks and we\u2019ve implemented our own Burst Protection feature which only logs some of the errors, if thousands and thousands of messages are received from the same customer within a short period of time.\n\n\nThe reason for our API being fast, is caused by the fact that all messages are handled asynchronously. We use Azure Service Bus to handle messages, since that supports a publish/subscribe setup where multiple subscribers can consume the same message. We have multiple consumers able to store messages in various data stores, send mails, etc. All of our consumers are able to run in multiple instances, which makes it easy to spin up new consumer instances if the system has a hard time getting all of the messages processed. At the moment we have two consumers indexing data in Elasticsearch, but it can be a different number if you ask us a week from now.\n\n\nMost of the features on elmah.io are based on searches in the awesome full-text server Elasticsearch. Elasticsearch is able to index millions of documents and make them searchable with query performance in few milliseconds. We use Azure Virtual Machines to host Elasticsearch and like the rest of the architecture, we can scale the number of nodes in the cluster depending on the need. Scaling of Elasticsearch nodes is not something we do automatically, but we continuously monitor the system and scale when needed. A single Elasticsearch node can handle a large amount of documents, but by replicating across multiple nodes, it makes it possible to do maintenance on a single node, without any down time for the end user.\n\n\nElasticsearch is backed up daily, using the \nAzure plugin\n for Elasticsearch and Azure Blob Storage. This way we are able to restore one or more indexes, if something goes really bad.\n\n\nAlongside Elasticsearch, we also store all messages in Azure Blob Storage. We like the idea of keeping customer data in at least two data stores. In cases where Elasticsearch data is lost and the backup cannot be used to restore the indexes, we are able to restore everything from Azure Blob Storage. Luckily we\u2019ve never actually needed to use data in Blob Storage, but having the data makes it a lot easier to sleep at night :) Blob Storage is a nice place to store data since it\u2019s highly scalable and geo replicated.\n\n\nThat wraps it up. We\u2019ve done everything in our power to make elmah.io scalable. Using a solution like Windows Azure where something that we thought a lot about when launching. It seemed expensive at the time, but when looking back, we would\u2019ve used a lot more developer hours in order to achieve the same scalable architecture using a homemade setup on cheap virtual machines somewhere else.\n\n\nFuture\n\n\nWe are quite confident that our current architecture will handle the increased load for at least a year, but as we see an increase in customers, we also will see increase in data. Since we don\u2019t want to sit our hands waiting for accidents to happen, we are already working to improve the architecture even more. In the next version of the API (version 3) we want to split the website and API in two parts. This would allow our website to be down, without the API being affected.\n\n\nWe also want to look more into the Traffic Manager in Windows Azure, which makes it possible to scale websites across multiple regions. This improves response time for our customers, since web requests are handled by the nearest data center.\n\n\nA third improvement could be to our service bus, which potentially can be a bottleneck in our current architecture. We are working on multiple ways to address this. One thing is to collect failing requests to the elmah.io API in the .NET client. In fact we already implemented this in the \nlatest prerelease\n. Another area could be to scale Service Bus or switch to another messaging technology like RabbitMQ. But since a service bus is the least of our worries at the moments, changes to this component probably won\u2019t be the first to see the light of day.", 
            "title": "Building a salable architecture to handle millions of errors"
        }, 
        {
            "location": "/Building-a-salable-architecture-to-handle-millions-of-errors/#building-a-salable-architecture-to-handle-millions-of-errors", 
            "text": "You may take it for granted, but building an architecture which is able to scale to millions of messages isn\u2019t something that comes overnight. elmah.io is built to handle lots and lots of messages by utilizing some of the nice features of Windows Azure. In this post we\u2019ll show you how we\u2019ve designed elmah.io to consume errors from our customers.  During the last 1\u00bd years, we\u2019ve continuously improved our architecture to handle an increasing load. Like every other startup, we didn\u2019t have the perfect architecture from day one. But we learned from our mistakes and now have a scalable architecture, which is able to handle our customer\u2019s data. A picture is worth a thousand words, and that is why looking at a diagram is probably the best way to explain our architecture:   The diagram illustrates the message flow from receiving a message (typically an error) from a customer, until the entire thing is persisted in the backend. We have a few components for handling emails and business rules that are not included in the diagram in order to keep it simple.  All messages are received through our  API . The API is running as part of the elmah.io web application as an Azure Website. Azure Websites have a nice scaling feature, which makes it possible to increase the number of instances dynamically, based on the load on the web server. Since we don\u2019t do much other than send messages to the service bus, we rarely need to scale the number of webservers, but in situations where one of our customers experience a DDOS attack, they may indirectly start DOS attacking us by sending a lot of errors to the elmah.io API. In these situations, scaling this number of websites is extremely important, to avoid the remaining customers being punished by a single DDOS. We rely on Windows Azures to load balancers to handle any DDOS attacks and we\u2019ve implemented our own Burst Protection feature which only logs some of the errors, if thousands and thousands of messages are received from the same customer within a short period of time.  The reason for our API being fast, is caused by the fact that all messages are handled asynchronously. We use Azure Service Bus to handle messages, since that supports a publish/subscribe setup where multiple subscribers can consume the same message. We have multiple consumers able to store messages in various data stores, send mails, etc. All of our consumers are able to run in multiple instances, which makes it easy to spin up new consumer instances if the system has a hard time getting all of the messages processed. At the moment we have two consumers indexing data in Elasticsearch, but it can be a different number if you ask us a week from now.  Most of the features on elmah.io are based on searches in the awesome full-text server Elasticsearch. Elasticsearch is able to index millions of documents and make them searchable with query performance in few milliseconds. We use Azure Virtual Machines to host Elasticsearch and like the rest of the architecture, we can scale the number of nodes in the cluster depending on the need. Scaling of Elasticsearch nodes is not something we do automatically, but we continuously monitor the system and scale when needed. A single Elasticsearch node can handle a large amount of documents, but by replicating across multiple nodes, it makes it possible to do maintenance on a single node, without any down time for the end user.  Elasticsearch is backed up daily, using the  Azure plugin  for Elasticsearch and Azure Blob Storage. This way we are able to restore one or more indexes, if something goes really bad.  Alongside Elasticsearch, we also store all messages in Azure Blob Storage. We like the idea of keeping customer data in at least two data stores. In cases where Elasticsearch data is lost and the backup cannot be used to restore the indexes, we are able to restore everything from Azure Blob Storage. Luckily we\u2019ve never actually needed to use data in Blob Storage, but having the data makes it a lot easier to sleep at night :) Blob Storage is a nice place to store data since it\u2019s highly scalable and geo replicated.  That wraps it up. We\u2019ve done everything in our power to make elmah.io scalable. Using a solution like Windows Azure where something that we thought a lot about when launching. It seemed expensive at the time, but when looking back, we would\u2019ve used a lot more developer hours in order to achieve the same scalable architecture using a homemade setup on cheap virtual machines somewhere else.  Future  We are quite confident that our current architecture will handle the increased load for at least a year, but as we see an increase in customers, we also will see increase in data. Since we don\u2019t want to sit our hands waiting for accidents to happen, we are already working to improve the architecture even more. In the next version of the API (version 3) we want to split the website and API in two parts. This would allow our website to be down, without the API being affected.  We also want to look more into the Traffic Manager in Windows Azure, which makes it possible to scale websites across multiple regions. This improves response time for our customers, since web requests are handled by the nearest data center.  A third improvement could be to our service bus, which potentially can be a bottleneck in our current architecture. We are working on multiple ways to address this. One thing is to collect failing requests to the elmah.io API in the .NET client. In fact we already implemented this in the  latest prerelease . Another area could be to scale Service Bus or switch to another messaging technology like RabbitMQ. But since a service bus is the least of our worries at the moments, changes to this component probably won\u2019t be the first to see the light of day.", 
            "title": "Building a salable architecture to handle millions of errors"
        }, 
        {
            "location": "/2013/12/Running ElasticSearch in a cluster on Azure/", 
            "text": "Running ElasticSearch in a cluster on Azure\n\n\nThomas Ardal\n, December 16, 2013\n\n\nThis is a cross post from \nthomasardal.com\n about how we\u2019ve setup elmah.io on Windows Azure.\n\n\nIn this post I will share my experiences setting up ElasticSearch in a clustered setup of virtual machines, running on Windows Azure. Disclamer: this is in no way an official guide on how to setup ElasticSearch in a cluster. My experience with replication in ElasticSearch is pretty limited, and I only just now found out how virtual networks work in Windows Azure. Use this guide for inspiration and I would love to get some feedback on the approach used.\n\n\nIf you don\u2019t have access to Azure, there\u2019s a free trial available from the frontpage: http://www.windowsazure.com/en-us/pricing/free-trial/. You will get 30 days of Azure with a maximum of $200 worth of services. Pricing on Azure has always been a nightmare, but $200 should do just fine in order to play around with a couple of VMs. When signed up and in, start by creating a new virtual network:\n\n\n\n\nInput a name and create a new affinity group. For now we will just input values and discuss the details later:\n\n\n\n\nIn the DNS Servers and VPN Connectivity step just click Next and Azure will control the DNS. The final step should look something like this:\n\n\n\n\nWhen finished click the Complete checkmark. So let\u2019s rewind and talk about what we have done here. The virtual network is not necessary in order for ElasticSearch to work, but it makes it a hell of a lot easier, because all of the virtual machines on the same network will be able to communicate with each other, without you should worry about anything than allowing the connections through the firewall. More about that later.\n\n\nI won\u2019t go into details about the affinity group, but you can read a great introduction to affinity groups on Azure here: \nhttp://convective.wordpress.com/2012/06/10/affinity-groups-in-windows-azure/\n. Just think of the affinity group as a single container at Microsoft. Having all of your services in the same container, improves performance when communicating between different computers inside that container.\n\n\nElasticSearch requires some iron to execute. Let\u2019s create a new virtual machine:\n\n\n\n\nWe want a data center edition of Windows to run our cluster:\n\n\n\n\nGive you VM a name and pick a size of your choice:\n\n\n\n\nIn the following step, we will use the new virtual network we just created. But before that, select the Create a new cloud service option from the Cloud Service select box. Cloud Services is a funny thing in Azure, because it maps to both a way of implementing web sites (web roles) and background jobs (worker roles) as well as to scale other services like virtual machines. In the Virtual Network select box, choose the elasticsearch-cluster network or whatever you decided to name it:\n\n\n\n\nLeave the endpoints as is and click the Complete check mark:\n\n\n\n\nA few minutes later, your virtual machine will be up and running. We could go on and install ElasticSearch now, but one machine doesn\u2019t smell like a cluster, right? You guessed what next: more VMs! I\u2019ve always considered two nodes running a piece of software in a cluster as safe, but my time at eBay taught me, that you\u2019d always want three nodes in a cluster. It\u2019s probably up for debate, but having only two nodes doesn\u2019t really make it a cluster every time you need to take one out for patching or similar. That\u2019s why we create two additional VMs. The steps are exactly the same as above, except the Cloud Service select box where you should choose the es-vms cloud service you\u2019ve already created.\n\n\nI\u2019m assuming that you have three VM\u2019s up and running:\n\n\n\n\nNow for the boring part: installing ElasticSearch. Actually it\u2019s quite simple, but I wont go into detail on it, because it\u2019s fairly well documented here in the \nInstallation part\n. You might argue that we could do with installing ElasticSearch on a single VM and using that as a template for the other two VMs. You\u2019re right! Azure supports creating new VMs from existing virtual discs, but I\u2019ve never really tried, why I don\u2019t want to write something rubbish. For now just install ElasticSearch on the three VMs.\n\n\nRemember when I told the advantages about added all of the VMs to the same virtual network?  Well now it\u2019s time to collect. ElasticSearch supports different types of discovery, which in plain words makes multiple ElasticSearch instances talk to each other. The default type of discovery is multicast where you do not need to configure anything. Unfortunately multicast doesn\u2019t seem to work on Azure (yet), why we need to configure this using unicast. On each VM, open the elasticsearch.yml located in the config directory of ElasticSearch and search for \n\u201c# discovery.zen.ping.multicast.enabled: false\u201d\n. In order for ElasticSearch to use unicast, uncomment this line. Also you need to setup the IPs of the other ElasticSearch instances in our virtual network. In my case, the following line does the trick:\n\n\ndiscovery.zen.ping.unicast.hosts: [\u201c10.0.0.4\u201d, \u201c10.0.0.5\u201d, \u201c10.0.0.6\u201d]\n\n\nThe IP addresses visible from the dashboard of each VM. Make sure that you pick the internal IPs. Finally you need to specify the same cluster name for all instances using this line:\n\n\ncluster.name: elasticsearch\n\n\nElasticSearch communicates between nodes on port 9300 and accepts connections from the outside on port 9200, why you need to allow inbound access on these ports in Windows Firewall. Copy the elasticsearch.yml around and start ElasticSearch on all the VMs. Congratulations! You now have your first ElasticSearch cluster up and running.\n\n\nTo communicate with your new cluster from a Azure website or something outside Microsofts datacenters, you need access to port port 9200 on all of the VMs. If you inspect the public IPs if all three VMs you will notice, that it\u2019s the same. All three ElasticSearch instances will be able to handle requests on this IP, but in order to do so, you need to configure load balancing on Azure. Load balancing in azure is implemented in a real simple way through Endpoints. Navigate to the endpoints tab of one of your VMs and create a new endpoint:\n\n\n\n\nIn the following step input a name and port 9200 in both Public and Private Port. Make sure to check the Create a load balanced set:\n\n\n\n\nIn the final step assign a name to the new load balanced endpoint and accept the default values in the rest of the fields:\n\n\n\n\nThe only thing missing is creating the same endpoint on the remaining two virtual machines. Remember to select the existing load balanced set when creating the new endpoints. This makes Azure load balance incoming request to port 9200 on the IP of the VMs.\n\n\nIn my setup I\u2019ve installed Head plugin for ElasticSearch, which makes it possible to visualize a new index on my cluster for you guys:", 
            "title": "Running ElasticSearch in a cluster on Azure"
        }, 
        {
            "location": "/2013/12/Running ElasticSearch in a cluster on Azure/#running-elasticsearch-in-a-cluster-on-azure", 
            "text": "Thomas Ardal , December 16, 2013", 
            "title": "Running ElasticSearch in a cluster on Azure"
        }, 
        {
            "location": "/2013/12/Running ElasticSearch in a cluster on Azure/#this-is-a-cross-post-from-thomasardalcom-about-how-weve-setup-elmahio-on-windows-azure", 
            "text": "In this post I will share my experiences setting up ElasticSearch in a clustered setup of virtual machines, running on Windows Azure. Disclamer: this is in no way an official guide on how to setup ElasticSearch in a cluster. My experience with replication in ElasticSearch is pretty limited, and I only just now found out how virtual networks work in Windows Azure. Use this guide for inspiration and I would love to get some feedback on the approach used.  If you don\u2019t have access to Azure, there\u2019s a free trial available from the frontpage: http://www.windowsazure.com/en-us/pricing/free-trial/. You will get 30 days of Azure with a maximum of $200 worth of services. Pricing on Azure has always been a nightmare, but $200 should do just fine in order to play around with a couple of VMs. When signed up and in, start by creating a new virtual network:   Input a name and create a new affinity group. For now we will just input values and discuss the details later:   In the DNS Servers and VPN Connectivity step just click Next and Azure will control the DNS. The final step should look something like this:   When finished click the Complete checkmark. So let\u2019s rewind and talk about what we have done here. The virtual network is not necessary in order for ElasticSearch to work, but it makes it a hell of a lot easier, because all of the virtual machines on the same network will be able to communicate with each other, without you should worry about anything than allowing the connections through the firewall. More about that later.  I won\u2019t go into details about the affinity group, but you can read a great introduction to affinity groups on Azure here:  http://convective.wordpress.com/2012/06/10/affinity-groups-in-windows-azure/ . Just think of the affinity group as a single container at Microsoft. Having all of your services in the same container, improves performance when communicating between different computers inside that container.  ElasticSearch requires some iron to execute. Let\u2019s create a new virtual machine:   We want a data center edition of Windows to run our cluster:   Give you VM a name and pick a size of your choice:   In the following step, we will use the new virtual network we just created. But before that, select the Create a new cloud service option from the Cloud Service select box. Cloud Services is a funny thing in Azure, because it maps to both a way of implementing web sites (web roles) and background jobs (worker roles) as well as to scale other services like virtual machines. In the Virtual Network select box, choose the elasticsearch-cluster network or whatever you decided to name it:   Leave the endpoints as is and click the Complete check mark:   A few minutes later, your virtual machine will be up and running. We could go on and install ElasticSearch now, but one machine doesn\u2019t smell like a cluster, right? You guessed what next: more VMs! I\u2019ve always considered two nodes running a piece of software in a cluster as safe, but my time at eBay taught me, that you\u2019d always want three nodes in a cluster. It\u2019s probably up for debate, but having only two nodes doesn\u2019t really make it a cluster every time you need to take one out for patching or similar. That\u2019s why we create two additional VMs. The steps are exactly the same as above, except the Cloud Service select box where you should choose the es-vms cloud service you\u2019ve already created.  I\u2019m assuming that you have three VM\u2019s up and running:   Now for the boring part: installing ElasticSearch. Actually it\u2019s quite simple, but I wont go into detail on it, because it\u2019s fairly well documented here in the  Installation part . You might argue that we could do with installing ElasticSearch on a single VM and using that as a template for the other two VMs. You\u2019re right! Azure supports creating new VMs from existing virtual discs, but I\u2019ve never really tried, why I don\u2019t want to write something rubbish. For now just install ElasticSearch on the three VMs.  Remember when I told the advantages about added all of the VMs to the same virtual network?  Well now it\u2019s time to collect. ElasticSearch supports different types of discovery, which in plain words makes multiple ElasticSearch instances talk to each other. The default type of discovery is multicast where you do not need to configure anything. Unfortunately multicast doesn\u2019t seem to work on Azure (yet), why we need to configure this using unicast. On each VM, open the elasticsearch.yml located in the config directory of ElasticSearch and search for  \u201c# discovery.zen.ping.multicast.enabled: false\u201d . In order for ElasticSearch to use unicast, uncomment this line. Also you need to setup the IPs of the other ElasticSearch instances in our virtual network. In my case, the following line does the trick:  discovery.zen.ping.unicast.hosts: [\u201c10.0.0.4\u201d, \u201c10.0.0.5\u201d, \u201c10.0.0.6\u201d]  The IP addresses visible from the dashboard of each VM. Make sure that you pick the internal IPs. Finally you need to specify the same cluster name for all instances using this line:  cluster.name: elasticsearch  ElasticSearch communicates between nodes on port 9300 and accepts connections from the outside on port 9200, why you need to allow inbound access on these ports in Windows Firewall. Copy the elasticsearch.yml around and start ElasticSearch on all the VMs. Congratulations! You now have your first ElasticSearch cluster up and running.  To communicate with your new cluster from a Azure website or something outside Microsofts datacenters, you need access to port port 9200 on all of the VMs. If you inspect the public IPs if all three VMs you will notice, that it\u2019s the same. All three ElasticSearch instances will be able to handle requests on this IP, but in order to do so, you need to configure load balancing on Azure. Load balancing in azure is implemented in a real simple way through Endpoints. Navigate to the endpoints tab of one of your VMs and create a new endpoint:   In the following step input a name and port 9200 in both Public and Private Port. Make sure to check the Create a load balanced set:   In the final step assign a name to the new load balanced endpoint and accept the default values in the rest of the fields:   The only thing missing is creating the same endpoint on the remaining two virtual machines. Remember to select the existing load balanced set when creating the new endpoints. This makes Azure load balance incoming request to port 9200 on the IP of the VMs.  In my setup I\u2019ve installed Head plugin for ElasticSearch, which makes it possible to visualize a new index on my cluster for you guys:", 
            "title": "This is a cross post from thomasardal.com about how we\u2019ve setup elmah.io on Windows Azure."
        }, 
        {
            "location": "/2013/09/ELMAH Elasticsearch Tutorial/", 
            "text": "ELMAH Elasticsearch Tutorial\n\n\nThis article shows how Elasticsearch can be used as a logging backend for ELMAH. A basic knowledge about ELMAH is a prerequisite to reading this article. If you\u2019re new to ELMAH, please read our \nELMAH Tutorial\n.\n\n\nThomas Ardal\n, September 4. 2013\n\n\nElasticsearch\n\n\nSo what\u2019s \nElasticsearch\n and why is it ideal for storing ELMAH errors? To answer the first question, Elasticsearch is a powerful search engine based on Lucene indexes. Why do we think it\u2019s ideal to store ELMAH errors? Well because of three things in fact: Search, Search and Search! Nobody wants to log errors from their webserver, without being able to search them. Elasticsearch provides some really kick-ass search mechanisms, which simply isn\u2019t possible in a SQL Database or requires a lot of knowledge about configuring individual products.\n\n\nElmah.Io.Elasticsearch\n\n\nAt \nelmah.io\n we love ELMAH and Elasticsearch so much, that we wrote our own implementation of a ELMAH error logger for Elasticsearch. The code is \nopen sourced\n at GitHub and we accept pull requests as well as feature requests like pretty much any other open source project. Elmah.Io.Elasticsearch is in fact a competitor to elmah.io itself, because you could build your own UI on top of our NuGet package. We believe that our product is strong enough for you to want to try it out anyway.\n\n\nElmah.Io.Elasticsearch is distributed through NuGet and works like any other error log implementation for ELMAH. Before we start looking at the ELMAH configuration, let\u2019s install Elasticsearch.\n\n\nInstallation\n\n\nBefore installing Elasticsearch, you need to install a Java JRE. We know it sounds like a world of pain, but Elasticsearch is based on Java and therefore require you to install it :( Just do us a favor and unclick the option which tries to cheat you into installing the Ask toolbar. Java is downloaded from the \ndownload page\n.\n\n\nNow that we forever infected our machine (3 billion devices is infected with Java, right?), we are ready to install Elasticsearch. Head over to the \nElasticsearch download page\n and download the Zip. When downloaded unpack the zip somewhere on your hard drive. Locate the bin folder and double click elasticsearch.bat. If everything have been setup correctly (you probably will experience some sort of obscure Java problem like JAVA_HOME not being specified), Elasticsearch should startup in a new command prompt:\n\n\n\n\nHooray! Elasticsearch is running.\n\n\nConfiguring ELMAH\n\n\nWe know we promised some configuration. Before doing that you need to install the Elmah.Elasticsearch NuGet package (name differ to align with other storage packages for ELMAH):\n\n\nInstall-Package Elmah.Elasticsearch\n\n\n\n\n... and now for the XML. The downloaded NuGet packages already added a hell of a lot of XML to your web.config. In order for ELMAH to use the Elasticsearch error logger, located in the Elmah.Io.Elasticsearch assembly, locate the \nelmah\n element and make it look like so:\n\n\nelmah\n\n  \nerrorLog\n    type=\nElmah.Io.Elasticsearch.ElasticsearchErrorLog, Elmah.Io.Elasticsearch\n\n    connectionStringName=\nElmahIoElasticsearch\n /\n\n\n/elmah\n\n\n\n\n\nNotice something missing? You\u2019re right! The connection string to Elasticsearch specified in line 4. That little sucker is actually a name pointer to a standard connection string in the web.config:\n\n\nconnectionStrings\n\n  \nadd name=\nElmahIoElasticsearch\n connectionString=\nhttp://localhost:9200\n/\n\n\n/connectionStrings\n\n\n\n\n\nThere you have it. ELMAH is now configured to use Elasticsearch using the Elmah.Io.Elasticsearch package. It doesn\u2019t get much easier than that. You can use the default UI in ELMAH by accessing /elmah.axd in your browser. Doing that can be fine, but doesn\u2019t really provide you with the strong search capabilities that we promissed you earlier. Elasticsearch comes with a UI called Head, which can help you do those funky searched. Unfortunatly you need to install Head yourself, but it\u2019s a no brainer using this \ninstallation guide\n.", 
            "title": "ELMAH Elasticsearch Tutorial"
        }, 
        {
            "location": "/2013/09/ELMAH Elasticsearch Tutorial/#elmah-elasticsearch-tutorial", 
            "text": "", 
            "title": "ELMAH Elasticsearch Tutorial"
        }, 
        {
            "location": "/2013/09/ELMAH Elasticsearch Tutorial/#this-article-shows-how-elasticsearch-can-be-used-as-a-logging-backend-for-elmah-a-basic-knowledge-about-elmah-is-a-prerequisite-to-reading-this-article-if-youre-new-to-elmah-please-read-our-elmah-tutorial", 
            "text": "Thomas Ardal , September 4. 2013  Elasticsearch  So what\u2019s  Elasticsearch  and why is it ideal for storing ELMAH errors? To answer the first question, Elasticsearch is a powerful search engine based on Lucene indexes. Why do we think it\u2019s ideal to store ELMAH errors? Well because of three things in fact: Search, Search and Search! Nobody wants to log errors from their webserver, without being able to search them. Elasticsearch provides some really kick-ass search mechanisms, which simply isn\u2019t possible in a SQL Database or requires a lot of knowledge about configuring individual products.  Elmah.Io.Elasticsearch  At  elmah.io  we love ELMAH and Elasticsearch so much, that we wrote our own implementation of a ELMAH error logger for Elasticsearch. The code is  open sourced  at GitHub and we accept pull requests as well as feature requests like pretty much any other open source project. Elmah.Io.Elasticsearch is in fact a competitor to elmah.io itself, because you could build your own UI on top of our NuGet package. We believe that our product is strong enough for you to want to try it out anyway.  Elmah.Io.Elasticsearch is distributed through NuGet and works like any other error log implementation for ELMAH. Before we start looking at the ELMAH configuration, let\u2019s install Elasticsearch.  Installation  Before installing Elasticsearch, you need to install a Java JRE. We know it sounds like a world of pain, but Elasticsearch is based on Java and therefore require you to install it :( Just do us a favor and unclick the option which tries to cheat you into installing the Ask toolbar. Java is downloaded from the  download page .  Now that we forever infected our machine (3 billion devices is infected with Java, right?), we are ready to install Elasticsearch. Head over to the  Elasticsearch download page  and download the Zip. When downloaded unpack the zip somewhere on your hard drive. Locate the bin folder and double click elasticsearch.bat. If everything have been setup correctly (you probably will experience some sort of obscure Java problem like JAVA_HOME not being specified), Elasticsearch should startup in a new command prompt:   Hooray! Elasticsearch is running.  Configuring ELMAH  We know we promised some configuration. Before doing that you need to install the Elmah.Elasticsearch NuGet package (name differ to align with other storage packages for ELMAH):  Install-Package Elmah.Elasticsearch  ... and now for the XML. The downloaded NuGet packages already added a hell of a lot of XML to your web.config. In order for ELMAH to use the Elasticsearch error logger, located in the Elmah.Io.Elasticsearch assembly, locate the  elmah  element and make it look like so:  elmah \n   errorLog\n    type= Elmah.Io.Elasticsearch.ElasticsearchErrorLog, Elmah.Io.Elasticsearch \n    connectionStringName= ElmahIoElasticsearch  /  /elmah   Notice something missing? You\u2019re right! The connection string to Elasticsearch specified in line 4. That little sucker is actually a name pointer to a standard connection string in the web.config:  connectionStrings \n   add name= ElmahIoElasticsearch  connectionString= http://localhost:9200 /  /connectionStrings   There you have it. ELMAH is now configured to use Elasticsearch using the Elmah.Io.Elasticsearch package. It doesn\u2019t get much easier than that. You can use the default UI in ELMAH by accessing /elmah.axd in your browser. Doing that can be fine, but doesn\u2019t really provide you with the strong search capabilities that we promissed you earlier. Elasticsearch comes with a UI called Head, which can help you do those funky searched. Unfortunatly you need to install Head yourself, but it\u2019s a no brainer using this  installation guide .", 
            "title": "This article shows how Elasticsearch can be used as a logging backend for ELMAH. A basic knowledge about ELMAH is a prerequisite to reading this article. If you\u2019re new to ELMAH, please read our ELMAH Tutorial."
        }, 
        {
            "location": "/2013/08/another_elmah_tutorial/", 
            "text": "Does the world need another ELMAH tutorial?\n\n\nWe think it does!\n\n\nThomas Ardal\n, August 29. 2013\n\n\nThere are a lot of articles trying to explain ELMAH out there, but most of them assume that you already know about ELMAH. This article is an attempt to explain how to get up and running with ELMAH in the simplest possible way.\n\n\nSo let\u2019s start by talking about what ELMAH is. ELMAH is basically a NuGet package for .NET web applications, logging every exception occurring on one or more websites to some storage of your choosing. Unlike other logging frameworks ELMAH will, when configured in its most simple form, log every exception automatically. Sure, there\u2019s an API you can use to log custom errors, but most people only use the automatic part. In this tutorial we will only focus on the basic parts.\n\n\nInstallation\n\n\nThe easiest way of setting up ELMAH is through NuGet.\n\n\nRun the following command:\n\n\nInstall-Package ELMAH\n\n\n\n\n\u2026 Or add ELMAH by right-clicking on References:\n\n\n\n\nand search for ELMAH:\n\n\n\n\nClick Install and ELMAH is installed in your project.\n\n\nA lot of configuration has been setup in your web.config, but for now just start your web project. When started, navigate to: http://localhost:port/elmah.axd (replace port with your web applications port number). You should see a website looking like this:\n\n\n\n\nLogging errors\n\n\nIn the default configuration, ELMAH uses an in-memory logger which means that errors on the webserver are logged in-memory only. The in-memory logger is meant for development only and we will look at configuring a persistent logger later in this article.\n\n\nFor now generate a 404 by inputting an URL not found like: http://localhost:port/generate-an-error. Unless you configured custom error pages, the default error page is shown:\n\n\n\n\nBehind the curtain, ELMAH silently hooked into the error event and logged the error.\n\n\nThe error list\n\n\nTry navigating to ELMAH again: http://localhost:port/elmah.axd:\n\n\n\n\nThe error just generated by accessing the illegal URL (/generate-an-error) now shows up on the list. ELMAH shows the most important variables in the table, but if you want the full picture, you can click the Details\u2026 link at the end of the error message. This will show ELMAH\u2019s details view:\n\n\n\n\nThe details view shows you some detailed information about the thrown error. Often you would head straight for the stacktrace, but sometimes debugging is easier if you look at the server variables (cookies, http headers etc.). Scroll down for a view of all the server variables included in the failing HTTP request:\n\n\n\n\nDone! Well, almost\u2026\n\n\nPerfect! Our new error log works as it should. If you can live with errors being logged in-memory, you can finish the tutorial now. However, remember that errors are cleared if your website is recycled or similar. Most people configure one of the supported logger implementations to be able to keep the errors. The chances that you are running a SQL Server are probably larger than any other database, which is why we chose to show the SQL Server logger in this tutorial. Please visit the official ELMAH site for a description of the other loggers.\n\n\nSetting up new loggers typically involve a bit of ELMAH configuration as well as some sort of connection string. Open your web.config file and locate the\n\n\nelement. The formatting may be a bit screwed up, but that is easily fixed by clicking Edit | Advanced | Format Document in Visual Studio. The markup looks like this:\n\n\nelmah\n\n  \n!--\n    See http://code.google.com/p/elmah/wiki/SecuringErrorLogPages for\n    more information on remote access and securing ELMAH.\n  --\n\n  \nsecurity allowRemoteAccess=\nfalse\n /\n\n\n/elmah\n\n\n\n\n\nGo ahead and delete the comment if you like. Notice that no logger configuration is present other than the security element. As mentioned before, ELMAH uses the in-memory logger when no logger has been specified. The allowRemoteAccess=\u201dfalse\u201d attribute on the security elements tells ELMAH not to allow connections to errors other than from localhost. You typically don\u2019t want to allow for others to look through you error log, which is why we advise you to keep these security settings.\n\n\nTo configure the SQL Server log, add a new error logger like this:\n\n\nelmah\n\n  \nerrorLog type=\nElmah.SqlErrorLog, Elmah\n connectionStringName=\nErrorLog\n/\n\n  \nsecurity allowRemoteAccess=\nfalse\n /\n\n\n/elmah\n\n\n\n\n\nIn line 2 a new element has been added. Every error logger in ELMAH is configured using this element. You can only have one error logger per project. The type attribute tells ELMAH what error logger to use. In this case we use the SqlErrorLog class from the Elmah assembly, which we already added through NuGet. Other error loggers may require you to add additional packages. The SqlErrorLog logger requires another attribute named connectionStringName. Again, different error loggers require different configuration to run. The connectionStringName should point to a SQL connection string name ErrorLog:\n\n\nconnectionStrings\n\n  \nadd\n    name=\nErrorLog\n\n    connectionString=\nData Source=localhost;Initial Catalog=ELMAH;Integrated Security=SSPI;\n\n    providerName=\nSystem.Data.SqlClient\n /\n\n\n/connectionStrings\n\n\n\n\n\nIn this example we chose to configure ELMAH to use its own database named ELMAH located on a SQL Server instance on localhost. We recommend using a separate database for ELMAH, but you can use your existing database if you like.\n\n\nELMAH requires some tables and stored procedures to be created on the configured database. The scripts for ELMAH 1.2 can be found here: \nELMAH v1.2 MS Sql Server DB script\n.", 
            "title": "Another ELMAH tutorial"
        }, 
        {
            "location": "/2013/08/another_elmah_tutorial/#does-the-world-need-another-elmah-tutorial", 
            "text": "", 
            "title": "Does the world need another ELMAH tutorial?"
        }, 
        {
            "location": "/2013/08/another_elmah_tutorial/#we-think-it-does", 
            "text": "Thomas Ardal , August 29. 2013  There are a lot of articles trying to explain ELMAH out there, but most of them assume that you already know about ELMAH. This article is an attempt to explain how to get up and running with ELMAH in the simplest possible way.  So let\u2019s start by talking about what ELMAH is. ELMAH is basically a NuGet package for .NET web applications, logging every exception occurring on one or more websites to some storage of your choosing. Unlike other logging frameworks ELMAH will, when configured in its most simple form, log every exception automatically. Sure, there\u2019s an API you can use to log custom errors, but most people only use the automatic part. In this tutorial we will only focus on the basic parts.  Installation  The easiest way of setting up ELMAH is through NuGet.  Run the following command:  Install-Package ELMAH  \u2026 Or add ELMAH by right-clicking on References:   and search for ELMAH:   Click Install and ELMAH is installed in your project.  A lot of configuration has been setup in your web.config, but for now just start your web project. When started, navigate to: http://localhost:port/elmah.axd (replace port with your web applications port number). You should see a website looking like this:   Logging errors  In the default configuration, ELMAH uses an in-memory logger which means that errors on the webserver are logged in-memory only. The in-memory logger is meant for development only and we will look at configuring a persistent logger later in this article.  For now generate a 404 by inputting an URL not found like: http://localhost:port/generate-an-error. Unless you configured custom error pages, the default error page is shown:   Behind the curtain, ELMAH silently hooked into the error event and logged the error.  The error list  Try navigating to ELMAH again: http://localhost:port/elmah.axd:   The error just generated by accessing the illegal URL (/generate-an-error) now shows up on the list. ELMAH shows the most important variables in the table, but if you want the full picture, you can click the Details\u2026 link at the end of the error message. This will show ELMAH\u2019s details view:   The details view shows you some detailed information about the thrown error. Often you would head straight for the stacktrace, but sometimes debugging is easier if you look at the server variables (cookies, http headers etc.). Scroll down for a view of all the server variables included in the failing HTTP request:   Done! Well, almost\u2026  Perfect! Our new error log works as it should. If you can live with errors being logged in-memory, you can finish the tutorial now. However, remember that errors are cleared if your website is recycled or similar. Most people configure one of the supported logger implementations to be able to keep the errors. The chances that you are running a SQL Server are probably larger than any other database, which is why we chose to show the SQL Server logger in this tutorial. Please visit the official ELMAH site for a description of the other loggers.  Setting up new loggers typically involve a bit of ELMAH configuration as well as some sort of connection string. Open your web.config file and locate the  element. The formatting may be a bit screwed up, but that is easily fixed by clicking Edit | Advanced | Format Document in Visual Studio. The markup looks like this:  elmah \n   !--\n    See http://code.google.com/p/elmah/wiki/SecuringErrorLogPages for\n    more information on remote access and securing ELMAH.\n  -- \n   security allowRemoteAccess= false  /  /elmah   Go ahead and delete the comment if you like. Notice that no logger configuration is present other than the security element. As mentioned before, ELMAH uses the in-memory logger when no logger has been specified. The allowRemoteAccess=\u201dfalse\u201d attribute on the security elements tells ELMAH not to allow connections to errors other than from localhost. You typically don\u2019t want to allow for others to look through you error log, which is why we advise you to keep these security settings.  To configure the SQL Server log, add a new error logger like this:  elmah \n   errorLog type= Elmah.SqlErrorLog, Elmah  connectionStringName= ErrorLog / \n   security allowRemoteAccess= false  /  /elmah   In line 2 a new element has been added. Every error logger in ELMAH is configured using this element. You can only have one error logger per project. The type attribute tells ELMAH what error logger to use. In this case we use the SqlErrorLog class from the Elmah assembly, which we already added through NuGet. Other error loggers may require you to add additional packages. The SqlErrorLog logger requires another attribute named connectionStringName. Again, different error loggers require different configuration to run. The connectionStringName should point to a SQL connection string name ErrorLog:  connectionStrings \n   add\n    name= ErrorLog \n    connectionString= Data Source=localhost;Initial Catalog=ELMAH;Integrated Security=SSPI; \n    providerName= System.Data.SqlClient  /  /connectionStrings   In this example we chose to configure ELMAH to use its own database named ELMAH located on a SQL Server instance on localhost. We recommend using a separate database for ELMAH, but you can use your existing database if you like.  ELMAH requires some tables and stored procedures to be created on the configured database. The scripts for ELMAH 1.2 can be found here:  ELMAH v1.2 MS Sql Server DB script .", 
            "title": "We think it does!"
        }, 
        {
            "location": "/changelog/20131227/", 
            "text": "elmah.io 20131227 released\n\n\nThomas Ardal\n, December 27, 2013\n\n\nA new release of elmah.io is out there waiting for you. Besides the usual minor tweaks and bugfixes, we have put all of our energy into a single large feature this time.\n\n\nIgnore Filters\n\n\nIf you are a regular elmah.io user (or even ELMAH using one of the build in persistors), you probably see irrelevant errors in your logs from time to time. Errors logged from different web crawlers like Googlebot and Bingbot, errors generated from your machine etc. Getting an overview of your log, can be extremely difficult if a lot of irrelevant errors are mingled with the important ones. At elmah.io we experienced this problem and decided to something about it: Please welcome Ignore Filters!\n\n\nIgnore filters let you ignore errors which matches a set of query parameters of your choosing. Ignore Filters can be found on the Filters tab beneath log settings:\n\n\n\n\nIn the top you will see all of the filters already added to you log. Beneath the list you can specify new filters by inputting a name and a \nLucene Query\n. In the buttom you will find the section \u201cAdd template filter\u201d which contains some of the most common filters to apply any log. In the above example, I have added the \u201cIgnore Googlebot\u201d filter to my log, meaning that no errors generated by a client with the specified user agent are logged.\n\n\nAs usual please reach out if you have ideas for elmah.io either through \nUserVoice\n, \nTwitter\n or \nEmail\n.", 
            "title": "December 27. 2013"
        }, 
        {
            "location": "/changelog/20131227/#elmahio-20131227-released", 
            "text": "Thomas Ardal , December 27, 2013", 
            "title": "elmah.io 20131227 released"
        }, 
        {
            "location": "/changelog/20131227/#a-new-release-of-elmahio-is-out-there-waiting-for-you-besides-the-usual-minor-tweaks-and-bugfixes-we-have-put-all-of-our-energy-into-a-single-large-feature-this-time", 
            "text": "Ignore Filters  If you are a regular elmah.io user (or even ELMAH using one of the build in persistors), you probably see irrelevant errors in your logs from time to time. Errors logged from different web crawlers like Googlebot and Bingbot, errors generated from your machine etc. Getting an overview of your log, can be extremely difficult if a lot of irrelevant errors are mingled with the important ones. At elmah.io we experienced this problem and decided to something about it: Please welcome Ignore Filters!  Ignore filters let you ignore errors which matches a set of query parameters of your choosing. Ignore Filters can be found on the Filters tab beneath log settings:   In the top you will see all of the filters already added to you log. Beneath the list you can specify new filters by inputting a name and a  Lucene Query . In the buttom you will find the section \u201cAdd template filter\u201d which contains some of the most common filters to apply any log. In the above example, I have added the \u201cIgnore Googlebot\u201d filter to my log, meaning that no errors generated by a client with the specified user agent are logged.  As usual please reach out if you have ideas for elmah.io either through  UserVoice ,  Twitter  or  Email .", 
            "title": "A new release of elmah.io is out there waiting for you. Besides the usual minor tweaks and bugfixes, we have put all of our energy into a single large feature this time."
        }, 
        {
            "location": "/changelog/20131212/", 
            "text": "elmah.io 20131212 released\n\n\nThomas Ardal\n, December 12, 2013\n\n\nWe just released elmah.io. The new release primarily contain bug fixes and we want to thank all of you that found and reported bugs. Besides fixing bugs, we also upgraded to the latest versions of ASP.NET MVC and ASP.NET Web API. As always, please let us know if you experience any problems.\n\n\nHere are some new features for ya!\n\n\nHTTPS\n\n\nFinally! We now support SSL. Visit \nelmah.io\n for the secure version. You can still visit the website on the non-secure URL, but all of your errors logs are shipped through SSL when using the elmah.io NuGet package.\n\n\nRename Log\n\n\nQuite few of you asked for the possibility to rename a log. Well here you go:\n\n\n\n\nAs usual please reach out if you have ideas for elmah.io either through \nUserVoice\n, \nTwitter\n or \nEmail\n.", 
            "title": "December 12. 2013"
        }, 
        {
            "location": "/changelog/20131212/#elmahio-20131212-released", 
            "text": "Thomas Ardal , December 12, 2013", 
            "title": "elmah.io 20131212 released"
        }, 
        {
            "location": "/changelog/20131212/#we-just-released-elmahio-the-new-release-primarily-contain-bug-fixes-and-we-want-to-thank-all-of-you-that-found-and-reported-bugs-besides-fixing-bugs-we-also-upgraded-to-the-latest-versions-of-aspnet-mvc-and-aspnet-web-api-as-always-please-let-us-know-if-you-experience-any-problems", 
            "text": "Here are some new features for ya!  HTTPS  Finally! We now support SSL. Visit  elmah.io  for the secure version. You can still visit the website on the non-secure URL, but all of your errors logs are shipped through SSL when using the elmah.io NuGet package.  Rename Log  Quite few of you asked for the possibility to rename a log. Well here you go:   As usual please reach out if you have ideas for elmah.io either through  UserVoice ,  Twitter  or  Email .", 
            "title": "We just released elmah.io. The new release primarily contain bug fixes and we want to thank all of you that found and reported bugs. Besides fixing bugs, we also upgraded to the latest versions of ASP.NET MVC and ASP.NET Web API. As always, please let us know if you experience any problems."
        }, 
        {
            "location": "/changelog/20131111/", 
            "text": "elmah.io 20131111 released\n\n\nThomas Ardal\n, November 11, 2013\n\n\nA few weeks have passed and while we are working on some major improvements that we are not quite ready to show yet, we\u2019ve just released some goodies for you.\n\n\nPimped install\n\n\nInstalling elmah.io have always been piece of cake. Believe or not it just got easier. You still install the NuGet package, but you no longer need to modify your web.config file manually. During the installation of the elmah.io NuGet package, a dialog is shown making it possible for you to input your log id:\n\n\n\n\nWhen installed, all the necessary config is automatically added and pointing to your error log in the cloud!\n\n\nLucene searches\n\n\nYou probably already love the search field. Well we have the perfect way for you to reach nerdvana! The search field now accept Lucene queries, making it possible for you to input structured queries like:\n\n\n\n\nGitHub integration\n\n\nHappy GitHub like us? Great, you will love the new GitHub integration. Setup the base URL to your GitHub issue tracker beneath settings and create a new issue right from the error details:\n\n\n\n\nDelete errors\n\n\nYou\u2019ve always had the choice of hiding individual errors. Are you one of those who like your errors gone for good when you\u2019ve handled them, you will dig the new Delete button, also located in the error details menu.\n\n\nImproved API\n\n\nOur API seems like a popular feature for you guys. That\u2019s why we\u2019ve extended it to also talk XML.\n\n\nAs usual please reach out if you have ideas for elmah.io either through \nUserVoice\n, \nTwitter\n or \nEmail\n.", 
            "title": "November 11. 2013"
        }, 
        {
            "location": "/changelog/20131111/#elmahio-20131111-released", 
            "text": "Thomas Ardal , November 11, 2013", 
            "title": "elmah.io 20131111 released"
        }, 
        {
            "location": "/changelog/20131111/#a-few-weeks-have-passed-and-while-we-are-working-on-some-major-improvements-that-we-are-not-quite-ready-to-show-yet-weve-just-released-some-goodies-for-you", 
            "text": "Pimped install  Installing elmah.io have always been piece of cake. Believe or not it just got easier. You still install the NuGet package, but you no longer need to modify your web.config file manually. During the installation of the elmah.io NuGet package, a dialog is shown making it possible for you to input your log id:   When installed, all the necessary config is automatically added and pointing to your error log in the cloud!  Lucene searches  You probably already love the search field. Well we have the perfect way for you to reach nerdvana! The search field now accept Lucene queries, making it possible for you to input structured queries like:   GitHub integration  Happy GitHub like us? Great, you will love the new GitHub integration. Setup the base URL to your GitHub issue tracker beneath settings and create a new issue right from the error details:   Delete errors  You\u2019ve always had the choice of hiding individual errors. Are you one of those who like your errors gone for good when you\u2019ve handled them, you will dig the new Delete button, also located in the error details menu.  Improved API  Our API seems like a popular feature for you guys. That\u2019s why we\u2019ve extended it to also talk XML.  As usual please reach out if you have ideas for elmah.io either through  UserVoice ,  Twitter  or  Email .", 
            "title": "A few weeks have passed and while we are working on some major improvements that we are not quite ready to show yet, we\u2019ve just released some goodies for you."
        }, 
        {
            "location": "/changelog/20131015/", 
            "text": "elmah.io 20131015 released\n\n\nThomas Ardal\n, October 15, 2013\n\n\nOnce again we have been busy building the best cloud based error logger for you guys and girls.\n\n\nHere are the feature list:\n\n\nNew dashboard\n\n\nA lot of you have suggested improvements for the dashboard. We have listened and provided you with a new and hopefully much better and informative dashboard.\n\n\n\n\nEach ELMAH log now shows a graph of new errors during the last 24 hours directly on the desktop. We really hope that you like it.\n\n\nTabbed search\n\n\nWe have started splitting up different search entrances into separate tabs on the search page. There\u2019s the search filters you already know from the previous version:\n\n\n\n\nThe new statistics tab, which btw will be extended with new chart types in the near future:\n\n\n\n\nand finally a new shiny calendar view, showing you a calendar of the errors from the past 14 days:\n\n\n\n\nChange log access\n\n\nEver wanted to administrate log access on existing users? Now it\u2019s possible through the new feature in the Users tab:\n\n\n\n\nAs usual please reach out if you have ideas for elmah.io either through \nUserVoice\n, \nTwitter\n or \nEmail\n.", 
            "title": "October 15. 2013"
        }, 
        {
            "location": "/changelog/20131015/#elmahio-20131015-released", 
            "text": "Thomas Ardal , October 15, 2013", 
            "title": "elmah.io 20131015 released"
        }, 
        {
            "location": "/changelog/20131015/#once-again-we-have-been-busy-building-the-best-cloud-based-error-logger-for-you-guys-and-girls", 
            "text": "Here are the feature list:  New dashboard  A lot of you have suggested improvements for the dashboard. We have listened and provided you with a new and hopefully much better and informative dashboard.   Each ELMAH log now shows a graph of new errors during the last 24 hours directly on the desktop. We really hope that you like it.  Tabbed search  We have started splitting up different search entrances into separate tabs on the search page. There\u2019s the search filters you already know from the previous version:   The new statistics tab, which btw will be extended with new chart types in the near future:   and finally a new shiny calendar view, showing you a calendar of the errors from the past 14 days:   Change log access  Ever wanted to administrate log access on existing users? Now it\u2019s possible through the new feature in the Users tab:   As usual please reach out if you have ideas for elmah.io either through  UserVoice ,  Twitter  or  Email .", 
            "title": "Once again we have been busy building the best cloud based error logger for you guys and girls."
        }, 
        {
            "location": "/changelog/20130922/", 
            "text": "elmah.io 20130922 released\n\n\nThomas Ardal\n, September 8, 2013\n\n\nTime for another update on new elmah.io features.\n\n\nAPI\n\n\nA lot of you asked for it. Now it\u2019s there! The new \nAPI\n makes it possible to integrate with elmah.io from your own code. We\u2019ve published three examples on how to integrate with elmah.io at our \nGitHub repository\n.\n\n\nBrowser and OS icons on error details\n\n\nShow which browser and OS the user generating this error were using. Helps you spot trends in errors relating to certain browsers or operating systems.\n\n\n\n\nClear and Delete log moved to settings\n\n\nBy popular request, we\u2019ve moved the \u201cdangerous\u201d methods like Clear and Delete log from the dashboard to a new tab on settings.\n\n\n\n\nPricing and About page\n\n\nFrom the top menu you will be able to access both Pricing and About page. We haven\u2019t published details about the actual price yet and we would love to get your input on that. The about page tells a little about us.\n\n\nAs usual please reach out if you have ideas for elmah.io either through \nUserVoice\n, \nTwitter\n or \nEmail\n.", 
            "title": "September 22. 2013"
        }, 
        {
            "location": "/changelog/20130922/#elmahio-20130922-released", 
            "text": "Thomas Ardal , September 8, 2013", 
            "title": "elmah.io 20130922 released"
        }, 
        {
            "location": "/changelog/20130922/#time-for-another-update-on-new-elmahio-features", 
            "text": "API  A lot of you asked for it. Now it\u2019s there! The new  API  makes it possible to integrate with elmah.io from your own code. We\u2019ve published three examples on how to integrate with elmah.io at our  GitHub repository .  Browser and OS icons on error details  Show which browser and OS the user generating this error were using. Helps you spot trends in errors relating to certain browsers or operating systems.   Clear and Delete log moved to settings  By popular request, we\u2019ve moved the \u201cdangerous\u201d methods like Clear and Delete log from the dashboard to a new tab on settings.   Pricing and About page  From the top menu you will be able to access both Pricing and About page. We haven\u2019t published details about the actual price yet and we would love to get your input on that. The about page tells a little about us.  As usual please reach out if you have ideas for elmah.io either through  UserVoice ,  Twitter  or  Email .", 
            "title": "Time for another update on new elmah.io features."
        }, 
        {
            "location": "/changelog/20130908/", 
            "text": "elmah.io 20130908 released\n\n\nThomas Ardal\n, September 8, 2013\n\n\nWe just released a new version of elmah.io.\n\n\nWe have been busy building the best cloud enabled error log for .NET web applications. Here are some of the new features:\n\n\n\n\nA lot of you commented on the necessary URL when creating a new log. You now input a name when creating new logs, giving you the change to create logs like \u201cMy Site\u201d, \u201cMy Site Staging\u201d, \u201cMy Site localhost\u201d and so on.\n\n\nA lot of style changes based on your input. Our responsive design now supports monitors with larger resolutions as well.\n\n\nPreviously you would add a new user to your log using an email. You can still do that, but you will be presented with a search result, giving you a better chance to find the user which should be added.\n\n\nWe fixed all known bugs. Please help us and report bugs on our \nUserVoice\n.", 
            "title": "September 08. 2013"
        }, 
        {
            "location": "/changelog/20130908/#elmahio-20130908-released", 
            "text": "Thomas Ardal , September 8, 2013", 
            "title": "elmah.io 20130908 released"
        }, 
        {
            "location": "/changelog/20130908/#we-just-released-a-new-version-of-elmahio", 
            "text": "We have been busy building the best cloud enabled error log for .NET web applications. Here are some of the new features:   A lot of you commented on the necessary URL when creating a new log. You now input a name when creating new logs, giving you the change to create logs like \u201cMy Site\u201d, \u201cMy Site Staging\u201d, \u201cMy Site localhost\u201d and so on.  A lot of style changes based on your input. Our responsive design now supports monitors with larger resolutions as well.  Previously you would add a new user to your log using an email. You can still do that, but you will be presented with a search result, giving you a better chance to find the user which should be added.  We fixed all known bugs. Please help us and report bugs on our  UserVoice .", 
            "title": "We just released a new version of elmah.io."
        }
    ]
}